import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import time
import re

def is_regular_stock(name):
    """
    ì¼ë°˜ ì£¼ì‹ì¸ì§€ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜
    ETF, í€ë“œ, ì±„ê¶Œ ë“±ì„ ì œì™¸í•˜ê³  ìˆœìˆ˜ ì£¼ì‹ ì¢…ëª©ë§Œ ì„ ë³„
    """
    
    # ëª…ë°±í•œ ETF/í€ë“œ ë¸Œëœë“œëª…ë“¤
    etf_brands = [
        'KODEX', 'TIGER', 'KBSTAR', 'KOSEF', 'KINDEX', 'ARIRANG', 'HANARO',
        'RISE', 'ACE', 'KIWOOM', 'PLUS', 'SOL', 'WON', '1Q', 'ITF', 'BNK',
        'FOCUS', 'TREX', 'HK', 'íŒŒì›Œ', 'ë§ˆì´í‹°', 'DAISHIN343', 'ì•„ì´ì— ì—ì…‹',
        'KCGI', 'KBë°œí•´ì¸í”„ë¼', 'ë§¥ì¿¼ë¦¬ì¸í”„ë¼', 'ë§µìŠ¤ë¦¬ì–¼í‹°', 'í•œêµ­ANKORìœ ì „'
    ]
    
    # ETF/í€ë“œ ê´€ë ¨ í‚¤ì›Œë“œ
    fund_keywords = [
        'ETF', 'ETN', 'REIT', 'ë¦¬ì¸ ', 'í€ë“œ',
        'ì±„ê¶Œ', 'í†µì•ˆì±„', 'ë¬¼ê°€ì±„', 'ê¸ˆìœµì±„', 'êµ­ê³ ì±„', 'íšŒì‚¬ì±„',
        'ë‹¨ê¸°ìê¸ˆ', 'ë‹¨ê¸°í†µì•ˆì±„', 'ë‹¨ê¸°ê¸ˆìœµì±„', 'ì•¡í‹°ë¸Œ',
        'ìŠ¤íŒ©', 'SPAC'  # SPAC(íŠ¹ìˆ˜ëª©ì ì¸ìˆ˜íšŒì‚¬) ì¶”ê°€
    ]
    
    # íˆ¬ì ê´€ë ¨ í‚¤ì›Œë“œ (ì¼ë°˜ ì£¼ì‹ì—ëŠ” ì—†ëŠ”)
    investment_keywords = [
        'ì¸ë±ìŠ¤', 'í•©ì„±', 'ì„ ë¬¼', 'ì˜µì…˜', 'ì¸ë²„ìŠ¤', 'ë ˆë²„ë¦¬ì§€',
        'ì»¤ë²„ë“œì½œ', 'ìœ„í´ë¦¬ì»¤ë²„ë“œì½œ', 'ë°ì¼ë¦¬ì»¤ë²„ë“œì½œ', 'ê³ ì •ì»¤ë²„ë“œì½œ',
        'TOP', 'Plus', 'TR', 'í¬ì»¤ìŠ¤', 'í…Œë§ˆ', 'ë°¸ë¥˜', 'ì„±ì¥', 'ì†Œë¶€ì¥'
    ]
    
    # ì§€ìˆ˜ ê´€ë ¨ í‚¤ì›Œë“œ
    index_keywords = ['S&P', 'MSCI', 'CSI', 'FTSE', 'Nikkei', 'DAX', 'NASDAQ', 'SOLACTIVE', 'KRX']
    
    # êµ­ê°€/ì§€ì—­ ê´€ë ¨ (í•´ì™¸íˆ¬ì ETF)
    country_keywords = ['ë¯¸êµ­', 'ì¤‘êµ­', 'ì¼ë³¸', 'ë…ì¼', 'ì¸ë„', 'ê¸€ë¡œë²Œ', 'ì•„ì‹œì•„', 'ìœ ë¡œ']
    
    # 1. ETF ë¸Œëœë“œëª… ì²´í¬
    for brand in etf_brands:
        if name.startswith(brand):
            return False
    
    # 2. í€ë“œ/ì±„ê¶Œ í‚¤ì›Œë“œ ì²´í¬
    for keyword in fund_keywords:
        if keyword in name:
            return False
    
    # 3. íˆ¬ì ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
    for keyword in investment_keywords:
        if keyword in name:
            return False
    
    # 4. ì§€ìˆ˜ ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
    for keyword in index_keywords:
        if keyword in name:
            return False
    
    # 5. êµ­ê°€/ì§€ì—­ í‚¤ì›Œë“œ ì²´í¬ (ë‹¨, ì‹¤ì œ ê¸°ì—…ëª…ì— í¬í•¨ëœ ê²½ìš°ëŠ” ì˜ˆì™¸)
    for keyword in country_keywords:
        if keyword in name:
            # ì‹¤ì œ ê¸°ì—…ëª…ì˜ ì¼ë¶€ê°€ ì•„ë‹ˆë¼ íˆ¬ì ìƒí’ˆëª…ì¸ ê²½ìš°ë§Œ ì œì™¸
            if any(invest_word in name for invest_word in ['ë°°ë‹¹', 'ì„±ì¥', 'í…Œí¬', 'ë°˜ë„ì²´', 'ë‚˜ìŠ¤ë‹¥']):
                return False
    
    # 6. ì¦ê¶Œì‚¬ ìš´ìš© ìƒí’ˆ (ì‹¤ì œ ì¦ê¶ŒíšŒì‚¬ ì£¼ì‹ì€ ì œì™¸í•˜ì§€ ì•ŠìŒ)
    securities_products = [
        'NHíˆ¬ì', 'SKì¦ê¶Œ', 'ë©”ë¦¬ì¸ ', 'ë¯¸ë˜ì—ì…‹', 'ì‚¼ì„±ì„ ë¬¼', 'ì‹ í•œíˆ¬ì',
        'ìœ ì•ˆíƒ€', 'ìœ ì§„íˆ¬ì', 'í‚¤ì›€', 'í•˜ë‚˜ê¸ˆìœµ', 'í•œí™”íˆ¬ì',
        'KBì¦ê¶Œ', 'IBKíˆ¬ì', 'êµë³´ì¦ê¶Œ', 'ëŒ€ì‹ ì¦ê¶Œ', 'í˜„ëŒ€ì°¨ì¦ê¶Œ'
    ]
    
    for keyword in securities_products:
        if keyword in name and not ('ì¦ê¶Œ' in name or 'ê¸ˆìœµ' in name or 'ì€í–‰' in name):
            return False
    
    # 7. ê³ ë°°ë‹¹, ë°°ë‹¹ ê´€ë ¨ ìƒí’ˆ (ê°œë³„ ì£¼ì‹ì´ ì•„ë‹Œ í…Œë§ˆ ìƒí’ˆ)
    if 'ê³ ë°°ë‹¹' in name or ('ë°°ë‹¹' in name and any(word in name for word in ['TOP', 'Plus', 'ì„±ì¥', 'í‚¹'])):
        return False
    
    # 8. SPAC (íŠ¹ìˆ˜ëª©ì ì¸ìˆ˜íšŒì‚¬) ê´€ë ¨ íŒ¨í„´
    spac_patterns = [
        'ìŠ¤íŒ©', 'SPAC', 'ëª©ì ', 'ì¸ìˆ˜íšŒì‚¬', 'íŠ¹ìˆ˜ëª©ì '
    ]
    
    for pattern in spac_patterns:
        if pattern in name:
            return False
    
    # SPAC ëª…ëª… íŒ¨í„´: "íšŒì‚¬ëª…ìŠ¤íŒ©ìˆ«ìí˜¸" (ì˜ˆ: ì—”ì—ì´ì¹˜ìŠ¤íŒ©29í˜¸)
    if 'ìŠ¤íŒ©' in name and ('í˜¸' in name or any(char.isdigit() for char in name)):
        return False
    
    # 9. ê¸°íƒ€ íˆ¬ìíšŒì‚¬ íŒ¨í„´
    if 'íˆ¬ìíšŒì‚¬' in name or 'ìì‚°ìš´ìš©' in name:
        return False
    
    return True

def get_individual_stock_data(code, name):
    """ê°œë³„ ì¢…ëª© í˜ì´ì§€ì—ì„œ ìƒì„¸ ì¬ë¬´ ë°ì´í„° ìˆ˜ì§‘"""
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}
    
    try:
        url = f'https://finance.naver.com/item/main.naver?code={code}'
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ì´ˆê¸°í™” (18ê°œ ë°ì´í„° í•„ë“œ)
        data = {
            'PER': '', 'PBR': '', 'ROE': '', 'ì‹œê°€ì´ì•¡': '',
            'ë§¤ì¶œì•¡': '', 'ì˜ì—…ì´ìµ': '', 'ë‹¹ê¸°ìˆœì´ìµ': '', 
            'ë¶€ì±„ë¹„ìœ¨': '', 'ìœ ë³´ìœ¨': '', 'ë°°ë‹¹ìˆ˜ìµë¥ ': '', 'ë°°ë‹¹ê¸ˆ': '',
            '52ì£¼ìµœê³ ': '', '52ì£¼ìµœì €': '', 'ê±°ë˜ëŒ€ê¸ˆ': '',
            'ì™¸êµ­ì¸ë¹„ìœ¨': '', 'ê¸°ê´€ë¹„ìœ¨': '', 'ë² íƒ€': '', 'ì—…ì¢…': ''
        }
        
        # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì •ê·œì‹ìœ¼ë¡œ ë°ì´í„° ì°¾ê¸°
        page_text = soup.get_text()
        
        # ê¸°ë³¸ ì§€í‘œ ì¶”ì¶œ
        patterns = {
            'PER': r'PER[^\d]*?([+-]?\d+\.?\d*)ë°°',
            'PBR': r'PBR[^\d]*?([+-]?\d+\.?\d*)ë°°', 
            'ROE': r'ROE[^\d]*?([+-]?\d+\.?\d*)%?',
            'ì‹œê°€ì´ì•¡': r'ì‹œê°€ì´ì•¡[^\d]*?([,\d]+)ì–µ',
            'ë°°ë‹¹ìˆ˜ìµë¥ ': r'ë°°ë‹¹ìˆ˜ìµë¥ [^\d]*?([+-]?\d+\.?\d*)%',
            '52ì£¼ìµœê³ ': r'52ì£¼ìµœê³ [^\d]*?([,\d]+)',
            '52ì£¼ìµœì €': r'52ì£¼ìµœì €[^\d]*?([,\d]+)',
            'ë² íƒ€': r'ë² íƒ€[^\d]*?([+-]?\d+\.?\d*)',
            'ì™¸êµ­ì¸ë¹„ìœ¨': r'ì™¸êµ­ì¸[^\d]*?([+-]?\d+\.?\d*)%',
            'ê¸°ê´€ë¹„ìœ¨': r'ê¸°ê´€[^\d]*?([+-]?\d+\.?\d*)%'
        }
        
        for key, pattern in patterns.items():
            match = re.search(pattern, page_text)
            if match:
                data[key] = match.group(1).replace(',', '') if ',' in match.group(1) else match.group(1)
        
        # ì—…ì¢… ì •ë³´ ì¶”ì¶œ (ì¢…ëª©ëª… ê·¼ì²˜ì—ì„œ)
        sector_element = soup.select_one('.wrap_company h2 a')
        if sector_element:
            data['ì—…ì¢…'] = sector_element.get('title', '')
        
        # í…Œì´ë¸” ê¸°ë°˜ ìƒì„¸ ì¶”ì¶œ
        for table in soup.find_all('table'):
            for row in table.find_all('tr'):
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 2:
                    for i, cell in enumerate(cells[:-1]):
                        cell_text = cell.get_text(strip=True)
                        next_cell_text = cells[i+1].get_text(strip=True)
                        
                        # ì¬ë¬´ ì§€í‘œ ë§¤í•‘
                        field_mapping = {
                            'PER': ['PER', 'per'],
                            'PBR': ['PBR', 'pbr'],
                            'ROE': ['ROE', 'roe'],
                            'ì‹œê°€ì´ì•¡': ['ì‹œê°€ì´ì•¡'],
                            'ë§¤ì¶œì•¡': ['ë§¤ì¶œì•¡', 'ë§¤ì¶œ'],
                            'ì˜ì—…ì´ìµ': ['ì˜ì—…ì´ìµ'],
                            'ë‹¹ê¸°ìˆœì´ìµ': ['ë‹¹ê¸°ìˆœì´ìµ', 'ìˆœì´ìµ'],
                            'ë¶€ì±„ë¹„ìœ¨': ['ë¶€ì±„ë¹„ìœ¨'],
                            'ìœ ë³´ìœ¨': ['ìœ ë³´ìœ¨'],
                            'ë°°ë‹¹ìˆ˜ìµë¥ ': ['ë°°ë‹¹ìˆ˜ìµë¥ ', 'ë°°ë‹¹ë¥ '],
                            'ë°°ë‹¹ê¸ˆ': ['ë°°ë‹¹ê¸ˆ', 'í˜„ê¸ˆë°°ë‹¹'],
                            '52ì£¼ìµœê³ ': ['52ì£¼ìµœê³ ', '52ì£¼ ìµœê³ '],
                            '52ì£¼ìµœì €': ['52ì£¼ìµœì €', '52ì£¼ ìµœì €'],
                            'ê±°ë˜ëŒ€ê¸ˆ': ['ê±°ë˜ëŒ€ê¸ˆ'],
                            'ì™¸êµ­ì¸ë¹„ìœ¨': ['ì™¸êµ­ì¸', 'ì™¸êµ­ì¸ ë¹„ìœ¨'],
                            'ê¸°ê´€ë¹„ìœ¨': ['ê¸°ê´€', 'ê¸°ê´€ ë¹„ìœ¨'],
                            'ë² íƒ€': ['ë² íƒ€', 'Beta']
                        }
                        
                        for field, keywords in field_mapping.items():
                            if any(keyword in cell_text for keyword in keywords) and not data[field]:
                                # ìˆ«ì ì¶”ì¶œ
                                if field in ['ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ']:
                                    # ì–µì› ë‹¨ìœ„ ì²˜ë¦¬
                                    value_match = re.search(r'([,\d]+)ì–µ?ì›?', next_cell_text)
                                    if value_match:
                                        data[field] = value_match.group(1).replace(',', '')
                                elif field in ['52ì£¼ìµœê³ ', '52ì£¼ìµœì €', 'ê±°ë˜ëŒ€ê¸ˆ']:
                                    # ì¼ë°˜ ìˆ«ì (ì‰¼í‘œ ì œê±°)
                                    value_match = re.search(r'([,\d]+)', next_cell_text)
                                    if value_match:
                                        data[field] = value_match.group(1).replace(',', '')
                                elif field in ['ë¶€ì±„ë¹„ìœ¨', 'ìœ ë³´ìœ¨', 'ë°°ë‹¹ìˆ˜ìµë¥ ', 'ì™¸êµ­ì¸ë¹„ìœ¨', 'ê¸°ê´€ë¹„ìœ¨']:
                                    # í¼ì„¼íŠ¸ ê°’
                                    value_match = re.search(r'([+-]?\d+\.?\d*)%?', next_cell_text)
                                    if value_match:
                                        data[field] = value_match.group(1)
                                elif field in ['PER', 'PBR', 'ROE', 'ë² íƒ€']:
                                    # ë°°ìˆ˜ë‚˜ ë¹„ìœ¨
                                    value_match = re.search(r'([+-]?\d+\.?\d*)', next_cell_text)
                                    if value_match:
                                        data[field] = value_match.group(1)
                                elif field == 'ë°°ë‹¹ê¸ˆ':
                                    # ë°°ë‹¹ê¸ˆ (ì›)
                                    value_match = re.search(r'([,\d]+)ì›?', next_cell_text)
                                    if value_match:
                                        data[field] = value_match.group(1).replace(',', '')
        
        # ì¶”ê°€: ê¸°ì—…ê°œìš” í˜ì´ì§€ì—ì„œ ì—…ì¢… ì •ë³´ ë” ì •í™•íˆ ê°€ì ¸ì˜¤ê¸°
        if not data['ì—…ì¢…']:
            try:
                company_url = f'https://finance.naver.com/item/coinfo.naver?code={code}'
                company_response = requests.get(company_url, headers=headers)
                company_soup = BeautifulSoup(company_response.text, 'html.parser')
                
                # ì—…ì¢… ì •ë³´ ì¶”ì¶œ
                sector_info = company_soup.select_one('table.gline tr td')
                if sector_info:
                    sector_text = sector_info.get_text(strip=True)
                    if 'ì—…ì¢…' in sector_text:
                        data['ì—…ì¢…'] = sector_text.split('ì—…ì¢…')[-1].strip()
            except:
                pass  # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        
        return tuple(data.values())
        
    except Exception as e:
        print(f"{name} ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
        return ('',) * 18  # 18ê°œ ë¹ˆ ê°’ ë°˜í™˜

def get_stock_data():
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}
    stock_data = []
    
    for market_type in [0, 1]:
        market_name = "ì½”ìŠ¤í”¼" if market_type == 0 else "ì½”ìŠ¤ë‹¥"
        print(f"\n{market_name} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        # ì „ì²´ í˜ì´ì§€ ìˆ˜ í™•ì¸
        url = f'https://finance.naver.com/sise/sise_market_sum.naver?sosok={market_type}&page=1'
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        max_page = 1
        page_nav = soup.select('td.pgRR > a')
        if page_nav:
            max_page = int(page_nav[0]['href'].split('=')[-1])
        
        print(f"{market_name} ì „ì²´ í˜ì´ì§€ ìˆ˜: {max_page}")
        
        # ì „ì²´ í˜ì´ì§€ ìˆ˜ì§‘
        for page in range(1, max_page + 1):
            print(f"í˜ì´ì§€ {page}/{max_page} ìˆ˜ì§‘ ì¤‘...")
            url = f'https://finance.naver.com/sise/sise_market_sum.naver?sosok={market_type}&page={page}'
            response = requests.get(url, headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            rows = soup.select('table.type_2 tr')[1:]
            if not rows:
                break
            
            collected = 0
            for row in rows:
                cols = row.select('td')
                if len(cols) <= 1:
                    continue
                
                try:
                    name_element = cols[1].select_one('a')
                    if not name_element:
                        continue
                    
                    name = name_element.text.strip()
                    if not is_regular_stock(name):
                        continue
                    
                    code = name_element['href'].split('=')[-1]
                    current_price = cols[2].text.strip().replace(',', '')
                    current_volume = cols[9].text.strip().replace(',', '') if len(cols) > 9 else ''
                    
                    # ê°œë³„ ì¢…ëª© í˜ì´ì§€ì—ì„œ ìƒì„¸ ë°ì´í„° ìˆ˜ì§‘
                    time.sleep(0.3)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
                    (per, pbr, roe, market_cap, sales, operating_profit, net_income, 
                     debt_ratio, retention_ratio, dividend_yield, dividend,
                     high_52w, low_52w, trading_value, foreign_ratio, 
                     institutional_ratio, beta, sector) = get_individual_stock_data(code, name)
                    
                    # ETF/í€ë“œ ì¶”ê°€ í•„í„°ë§: PER, PBR, ROEê°€ ëª¨ë‘ ë¹„ì–´ìˆìœ¼ë©´ ì œì™¸
                    if not per and not pbr and not roe:
                        print(f"  - {name}: PER/PBR/ROE ë°ì´í„° ì—†ìŒ (ETF/í€ë“œë¡œ ì¶”ì •) - ì œì™¸")
                        continue
                    
                    # ì¼ë³„ ì‹œì„¸ í˜ì´ì§€ì—ì„œ ì „ì¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    time.sleep(0.1)
                    daily_url = f'https://finance.naver.com/item/sise_day.naver?code={code}'
                    daily_response = requests.get(daily_url, headers=headers)
                    daily_soup = BeautifulSoup(daily_response.text, 'html.parser')
                    
                    daily_rows = daily_soup.select('table.type2 tr')
                    valid_rows = [r for r in daily_rows if r.select('td.num')]
                    
                    prev_close = ''
                    prev_volume = ''
                    if len(valid_rows) >= 2:
                        yesterday_row = valid_rows[1]
                        yesterday_cols = yesterday_row.select('td.num')
                        if len(yesterday_cols) >= 6:
                            prev_close = yesterday_cols[0].text.strip().replace(',', '')
                            prev_volume = yesterday_cols[5].text.strip().replace(',', '')
                    
                    if all([name, code, current_price]):
                        stock_data.append({
                            'ì¢…ëª©ëª…': name,
                            'ì¢…ëª©ì½”ë“œ': code,
                            'ì‹œì¥êµ¬ë¶„': market_name,
                            'ì—…ì¢…': sector,
                            'í˜„ì¬ê°€': current_price,
                            'ì „ì¼ì¢…ê°€': prev_close,
                            'ê±°ë˜ëŸ‰': current_volume,
                            'ì „ì¼ê±°ë˜ëŸ‰': prev_volume,
                            'ê±°ë˜ëŒ€ê¸ˆ': trading_value,
                            'PER': per,
                            'PBR': pbr,
                            'ROE': roe,
                            'ì‹œê°€ì´ì•¡': market_cap,
                            'ë§¤ì¶œì•¡': sales,
                            'ì˜ì—…ì´ìµ': operating_profit,
                            'ë‹¹ê¸°ìˆœì´ìµ': net_income,
                            'ë¶€ì±„ë¹„ìœ¨': debt_ratio,
                            'ìœ ë³´ìœ¨': retention_ratio,
                            'ë°°ë‹¹ìˆ˜ìµë¥ ': dividend_yield,
                            'ë°°ë‹¹ê¸ˆ': dividend,
                            '52ì£¼ìµœê³ ': high_52w,
                            '52ì£¼ìµœì €': low_52w,
                            'ì™¸êµ­ì¸ë¹„ìœ¨': foreign_ratio,
                            'ê¸°ê´€ë¹„ìœ¨': institutional_ratio,
                            'ë² íƒ€': beta,
                            'ìˆ˜ì§‘ì¼ì': datetime.now().strftime('%Y-%m-%d')
                        })
                        collected += 1
                        
                        # ì§„í–‰ìƒí™© ì¶œë ¥
                        if collected % 10 == 0:
                            print(f"  - {collected}ê°œ ì¢…ëª© ìˆ˜ì§‘ ì™„ë£Œ (ìµœê·¼: {name} - ì—…ì¢…: {sector})")
                
                except Exception as e:
                    print(f"ì˜¤ë¥˜ ë°œìƒ - ì¢…ëª©: {name if 'name' in locals() else 'ì•Œ ìˆ˜ ì—†ìŒ'}, ì˜¤ë¥˜: {str(e)}")
                    continue
            
            print(f"í˜ì´ì§€ {page}ì—ì„œ {collected}ê°œ ì¢…ëª© ìˆ˜ì§‘ ì™„ë£Œ")
            
            # ì¤‘ê°„ ì €ì¥ (100í˜ì´ì§€ë§ˆë‹¤)
            if page % 100 == 0:
                temp_df = pd.DataFrame(stock_data)
                temp_filename = f'temp_stock_data_{datetime.now().strftime("%Y%m%d_%H%M")}_{page}.xlsx'
                temp_df.to_excel(temp_filename, index=False)
                print(f"ì¤‘ê°„ ì €ì¥: {temp_filename}")
    
    return stock_data

def main():
    print("=== ì „ì²´ ì¢…ëª© ìƒì„¸ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ===")
    print("ìˆ˜ì§‘ ë°ì´í„°: 25ê°œ í•„ë“œ (ì¬ë¬´ì§€í‘œ, íˆ¬ììì •ë³´, ë°°ë‹¹ì •ë³´ ë“±)")
    print("ì˜ˆìƒ ì†Œìš”ì‹œê°„: 3-4ì‹œê°„ (ì „ì²´ ì¢…ëª© ì•½ 2000-3000ê°œ)")
    print("ì£¼ì˜: ìˆ˜ì§‘ ì¤‘ ì¤‘ë‹¨í•˜ì§€ ë§ˆì„¸ìš”. 100í˜ì´ì§€ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥ë©ë‹ˆë‹¤.\n")
    
    start_time = datetime.now()
    stock_data = get_stock_data()
    end_time = datetime.now()
    
    if stock_data:
        df = pd.DataFrame(stock_data)
        filename = f'full_stock_data_detailed_{datetime.now().strftime("%Y%m%d_%H%M")}.xlsx'
        df.to_excel(filename, index=False)
        
        print(f"\nğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ì´ {len(stock_data)}ê°œ ì¢…ëª©ì˜ ìƒì„¸ ë°ì´í„°ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ì†Œìš”ì‹œê°„: {end_time - start_time}")
        
        # ë°ì´í„° í’ˆì§ˆ í™•ì¸
        print(f"\nğŸ“Š ë°ì´í„° í’ˆì§ˆ:")
        print(f"PER ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['PER'].notna().sum()}/{len(df)}")
        print(f"PBR ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['PBR'].notna().sum()}/{len(df)}")
        print(f"ROE ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['ROE'].notna().sum()}/{len(df)}")
        print(f"ì‹œê°€ì´ì•¡ ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['ì‹œê°€ì´ì•¡'].notna().sum()}/{len(df)}")
        print(f"ì—…ì¢… ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['ì—…ì¢…'].notna().sum()}/{len(df)}")
        print(f"ë§¤ì¶œì•¡ ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['ë§¤ì¶œì•¡'].notna().sum()}/{len(df)}")
        print(f"ë°°ë‹¹ìˆ˜ìµë¥  ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['ë°°ë‹¹ìˆ˜ìµë¥ '].notna().sum()}/{len(df)}")
        
        # ì‹œê°€ì´ì•¡ë³„ ë¶„í¬ í™•ì¸
        df['ì‹œê°€ì´ì•¡'] = pd.to_numeric(df['ì‹œê°€ì´ì•¡'], errors='coerce')
        print(f"\nğŸ“ˆ ì‹œê°€ì´ì•¡ ë¶„í¬:")
        print(f"10ì¡° ì´ìƒ ëŒ€í˜•ì£¼: {(df['ì‹œê°€ì´ì•¡'] >= 100000).sum()}ê°œ")
        print(f"1ì¡°~10ì¡° ì¤‘í˜•ì£¼: {((df['ì‹œê°€ì´ì•¡'] >= 10000) & (df['ì‹œê°€ì´ì•¡'] < 100000)).sum()}ê°œ")
        print(f"1ì¡° ë¯¸ë§Œ ì†Œí˜•ì£¼: {(df['ì‹œê°€ì´ì•¡'] < 10000).sum()}ê°œ")
        
        # ì—…ì¢…ë³„ ë¶„í¬ í™•ì¸
        print(f"\nğŸ¢ ì—…ì¢…ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
        sector_counts = df['ì—…ì¢…'].value_counts().head(10)
        for sector, count in sector_counts.items():
            print(f"{sector}: {count}ê°œ")
            
    else:
        print("\nìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()