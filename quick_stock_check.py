import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import time
import re
import gspread
from google.oauth2.service_account import Credentials
import numpy as np
import os

def is_regular_stock(name):
    """
    ì¼ë°˜ ì£¼ì‹ì¸ì§€ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜
    ETF, í€ë“œ, ì±„ê¶Œ ë“±ì„ ì œì™¸í•˜ê³  ìˆœìˆ˜ ì£¼ì‹ ì¢…ëª©ë§Œ ì„ ë³„
    """
    
    # ëª…ë°±í•œ ETF/í€ë“œ ë¸Œëœë“œëª…ë“¤
    etf_brands = [
        'KODEX', 'TIGER', 'KBSTAR', 'KOSEF', 'KINDEX', 'ARIRANG', 'HANARO',
        'RISE', 'ACE', 'KIWOOM', 'PLUS', 'SOL', 'WON', '1Q', 'ITF', 'BNK',
        'FOCUS', 'TREX', 'HK', 'íŒŒì›Œ', 'ë§ˆì´í‹°', 'DAISHIN343', 'ì•„ì´ì— ì—ì…‹',
        'KCGI', 'KBë°œí•´ì¸í”„ë¼', 'ë§¥ì¿¼ë¦¬ì¸í”„ë¼', 'ë§µìŠ¤ë¦¬ì–¼í‹°', 'í•œêµ­ANKORìœ ì „'
    ]
    
    # ETF/í€ë“œ ê´€ë ¨ í‚¤ì›Œë“œ
    fund_keywords = [
        'ETF', 'ETN', 'REIT', 'ë¦¬ì¸ ', 'í€ë“œ',
        'ì±„ê¶Œ', 'í†µì•ˆì±„', 'ë¬¼ê°€ì±„', 'ê¸ˆìœµì±„', 'êµ­ê³ ì±„', 'íšŒì‚¬ì±„',
        'ë‹¨ê¸°ìê¸ˆ', 'ë‹¨ê¸°í†µì•ˆì±„', 'ë‹¨ê¸°ê¸ˆìœµì±„', 'ì•¡í‹°ë¸Œ',
        'ìŠ¤íŒ©', 'SPAC'  # SPAC(íŠ¹ìˆ˜ëª©ì ì¸ìˆ˜íšŒì‚¬) ì¶”ê°€
    ]
    
    # íˆ¬ì ê´€ë ¨ í‚¤ì›Œë“œ (ì¼ë°˜ ì£¼ì‹ì—ëŠ” ì—†ëŠ”)
    investment_keywords = [
        'ì¸ë±ìŠ¤', 'í•©ì„±', 'ì„ ë¬¼', 'ì˜µì…˜', 'ì¸ë²„ìŠ¤', 'ë ˆë²„ë¦¬ì§€',
        'ì»¤ë²„ë“œì½œ', 'ìœ„í´ë¦¬ì»¤ë²„ë“œì½œ', 'ë°ì¼ë¦¬ì»¤ë²„ë“œì½œ', 'ê³ ì •ì»¤ë²„ë“œì½œ',
        'TOP', 'Plus', 'TR', 'í¬ì»¤ìŠ¤', 'í…Œë§ˆ', 'ë°¸ë¥˜', 'ì„±ì¥', 'ì†Œë¶€ì¥'
    ]
    
    # ì§€ìˆ˜ ê´€ë ¨ í‚¤ì›Œë“œ
    index_keywords = ['S&P', 'MSCI', 'CSI', 'FTSE', 'Nikkei', 'DAX', 'NASDAQ', 'SOLACTIVE', 'KRX']
    
    # êµ­ê°€/ì§€ì—­ ê´€ë ¨ (í•´ì™¸íˆ¬ì ETF)
    country_keywords = ['ë¯¸êµ­', 'ì¤‘êµ­', 'ì¼ë³¸', 'ë…ì¼', 'ì¸ë„', 'ê¸€ë¡œë²Œ', 'ì•„ì‹œì•„', 'ìœ ë¡œ']
    
    # 1. ETF ë¸Œëœë“œëª… ì²´í¬
    for brand in etf_brands:
        if name.startswith(brand):
            return False
    
    # 2. í€ë“œ/ì±„ê¶Œ í‚¤ì›Œë“œ ì²´í¬
    for keyword in fund_keywords:
        if keyword in name:
            return False
    
    # 3. íˆ¬ì ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
    for keyword in investment_keywords:
        if keyword in name:
            return False
    
    # 4. ì§€ìˆ˜ ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
    for keyword in index_keywords:
        if keyword in name:
            return False
    
    # 5. êµ­ê°€/ì§€ì—­ í‚¤ì›Œë“œ ì²´í¬ (ë‹¨, ì‹¤ì œ ê¸°ì—…ëª…ì— í¬í•¨ëœ ê²½ìš°ëŠ” ì˜ˆì™¸)
    for keyword in country_keywords:
        if keyword in name:
            # ì‹¤ì œ ê¸°ì—…ëª…ì˜ ì¼ë¶€ê°€ ì•„ë‹ˆë¼ íˆ¬ì ìƒí’ˆëª…ì¸ ê²½ìš°ë§Œ ì œì™¸
            if any(invest_word in name for invest_word in ['ë°°ë‹¹', 'ì„±ì¥', 'í…Œí¬', 'ë°˜ë„ì²´', 'ë‚˜ìŠ¤ë‹¥']):
                return False
    
    # 6. ì¦ê¶Œì‚¬ ìš´ìš© ìƒí’ˆ (ì‹¤ì œ ì¦ê¶ŒíšŒì‚¬ ì£¼ì‹ì€ ì œì™¸í•˜ì§€ ì•ŠìŒ)
    securities_products = [
        'NHíˆ¬ì', 'SKì¦ê¶Œ', 'ë©”ë¦¬ì¸ ', 'ë¯¸ë˜ì—ì…‹', 'ì‚¼ì„±ì„ ë¬¼', 'ì‹ í•œíˆ¬ì',
        'ìœ ì•ˆíƒ€', 'ìœ ì§„íˆ¬ì', 'í‚¤ì›€', 'í•˜ë‚˜ê¸ˆìœµ', 'í•œí™”íˆ¬ì',
        'KBì¦ê¶Œ', 'IBKíˆ¬ì', 'êµë³´ì¦ê¶Œ', 'ëŒ€ì‹ ì¦ê¶Œ', 'í˜„ëŒ€ì°¨ì¦ê¶Œ'
    ]
    
    for keyword in securities_products:
        if keyword in name and not ('ì¦ê¶Œ' in name or 'ê¸ˆìœµ' in name or 'ì€í–‰' in name):
            return False
    
    # 7. ê³ ë°°ë‹¹, ë°°ë‹¹ ê´€ë ¨ ìƒí’ˆ (ê°œë³„ ì£¼ì‹ì´ ì•„ë‹Œ í…Œë§ˆ ìƒí’ˆ)
    if 'ê³ ë°°ë‹¹' in name or ('ë°°ë‹¹' in name and any(word in name for word in ['TOP', 'Plus', 'ì„±ì¥', 'í‚¹'])):
        return False
    
    # 8. SPAC (íŠ¹ìˆ˜ëª©ì ì¸ìˆ˜íšŒì‚¬) ê´€ë ¨ íŒ¨í„´
    spac_patterns = [
        'ìŠ¤íŒ©', 'SPAC', 'ëª©ì ', 'ì¸ìˆ˜íšŒì‚¬', 'íŠ¹ìˆ˜ëª©ì '
    ]
    
    for pattern in spac_patterns:
        if pattern in name:
            return False
    
    # SPAC ëª…ëª… íŒ¨í„´: "íšŒì‚¬ëª…ìŠ¤íŒ©ìˆ«ìí˜¸" (ì˜ˆ: ì—”ì—ì´ì¹˜ìŠ¤íŒ©29í˜¸)
    if 'ìŠ¤íŒ©' in name and ('í˜¸' in name or any(char.isdigit() for char in name)):
        return False
    
    # 9. ê¸°íƒ€ íˆ¬ìíšŒì‚¬ íŒ¨í„´
    if 'íˆ¬ìíšŒì‚¬' in name or 'ìì‚°ìš´ìš©' in name:
        return False
    
    return True

class GoogleSheetsUploader:
    def __init__(self, credentials_file='credentials.json'):
        """êµ¬ê¸€ ì‹œíŠ¸ ì—…ë¡œë” ì´ˆê¸°í™”"""
        self.credentials_file = credentials_file
        self.gc = None
        self.setup_connection()
    
    def setup_connection(self):
        """êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„¤ì •"""
        try:
            scope = [
                'https://www.googleapis.com/auth/spreadsheets',
                'https://www.googleapis.com/auth/drive'
            ]
            
            if not os.path.exists(self.credentials_file):
                print(f"âŒ {self.credentials_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            creds = Credentials.from_service_account_file(self.credentials_file, scopes=scope)
            self.gc = gspread.authorize(creds)
            print("âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„±ê³µ!")
            return True
            
        except Exception as e:
            print(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            return False
    
    def create_or_get_spreadsheet(self, spreadsheet_name):
        """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ê¸°ì¡´ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì°¾ê¸°
            try:
                spreadsheet = self.gc.open(spreadsheet_name)
                print(f"ğŸ“‹ ê¸°ì¡´ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì‚¬ìš©: {spreadsheet_name}")
                return spreadsheet
            except gspread.SpreadsheetNotFound:
                # ìƒˆ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„±
                spreadsheet = self.gc.create(spreadsheet_name)
                print(f"ğŸ“ ìƒˆ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„±: {spreadsheet_name}")
                return spreadsheet
                
        except Exception as e:
            print(f"âŒ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„±/ì ‘ê·¼ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def clean_dataframe(self, df):
        """DataFrameì—ì„œ NaN ê°’ì„ ì²˜ë¦¬í•˜ì—¬ JSON í˜¸í™˜ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸°"""
        # DataFrame ë³µì‚¬
        df_clean = df.copy()
        
        # NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€ê²½
        df_clean = df_clean.fillna('')
        
        # inf, -inf ê°’ë„ ì²˜ë¦¬
        df_clean = df_clean.replace([np.inf, -np.inf], '')
        
        # ëª¨ë“  ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ JSON í˜¸í™˜ì„± ë³´ì¥
        for col in df_clean.columns:
            df_clean[col] = df_clean[col].astype(str)
            # 'nan' ë¬¸ìì—´ë„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€ê²½
            df_clean[col] = df_clean[col].replace('nan', '')
        
        return df_clean
    
    def upload_dataframe(self, df, spreadsheet_name, sheet_name):
        """ë°ì´í„°í”„ë ˆì„ì„ êµ¬ê¸€ ì‹œíŠ¸ì— ì—…ë¡œë“œ (NaN ê°’ ì²˜ë¦¬ í¬í•¨)"""
        try:
            spreadsheet = self.create_or_get_spreadsheet(spreadsheet_name)
            if not spreadsheet:
                return False
            
            # ì‹œíŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±
            try:
                worksheet = spreadsheet.worksheet(sheet_name)
                # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
                worksheet.clear()
            except gspread.WorksheetNotFound:
                # ìƒˆ ì‹œíŠ¸ ìƒì„±
                worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=2000, cols=30)
            
            # ë°ì´í„° ì—…ë¡œë“œ
            if len(df) > 0:
                # DataFrame ì •ë¦¬ (NaN ê°’ ì²˜ë¦¬)
                df_clean = self.clean_dataframe(df)
                
                # í—¤ë”ì™€ ë°ì´í„°ë¥¼ í•¨ê»˜ ì—…ë¡œë“œ
                data = [df_clean.columns.tolist()] + df_clean.values.tolist()
                
                # ìˆ˜ì •ëœ update ë°©ì‹
                worksheet.update(values=data, range_name='A1')
                
                print(f"âœ… '{sheet_name}' ì‹œíŠ¸ì— {len(df)}ê°œ í–‰ ì—…ë¡œë“œ ì™„ë£Œ!")
                return True
            else:
                print(f"âš ï¸ '{sheet_name}' ì‹œíŠ¸: ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return True
                
        except Exception as e:
            print(f"âŒ ì‹œíŠ¸ ì—…ë¡œë“œ ì‹¤íŒ¨ ({sheet_name}): {str(e)}")
            return False
    
    def get_spreadsheet_url(self, spreadsheet_name):
        """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URL ê°€ì ¸ì˜¤ê¸°"""
        try:
            spreadsheet = self.gc.open(spreadsheet_name)
            return spreadsheet.url
        except:
            return None

    def format_sheet_headers(self, spreadsheet_name, sheet_name):
        """ì‹œíŠ¸ í—¤ë” í¬ë§· ì„¤ì • (ì„ íƒì‚¬í•­)"""
        try:
            spreadsheet = self.gc.open(spreadsheet_name)
            worksheet = spreadsheet.worksheet(sheet_name)
            
            # í—¤ë” í–‰ êµµê²Œ ë§Œë“¤ê¸°
            worksheet.format('A1:Z1', {
                'textFormat': {'bold': True},
                'backgroundColor': {'red': 0.9, 'green': 0.9, 'blue': 0.9}
            })
            
            print(f"âœ… '{sheet_name}' ì‹œíŠ¸ í—¤ë” í¬ë§· ì ìš© ì™„ë£Œ!")
            return True
            
        except Exception as e:
            print(f"âš ï¸ í—¤ë” í¬ë§· ì ìš© ì‹¤íŒ¨ ({sheet_name}): {str(e)}")
            return False

def calculate_volume_change_rate(current_volume, prev_volume):
    """ê±°ë˜ëŸ‰ ì „ì¼ë¹„ ì¦ê°ìœ¨ ê³„ì‚°"""
    try:
        if not current_volume or not prev_volume or prev_volume == '0':
            return ''
        
        current = float(str(current_volume).replace(',', ''))
        previous = float(str(prev_volume).replace(',', ''))
        
        if previous == 0:
            return ''
        
        change_rate = ((current - previous) / previous) * 100
        return f"{change_rate:.2f}"
    except:
        return ''

def get_individual_stock_data(code, name):
    """ê°œë³„ ì¢…ëª© í˜ì´ì§€ì—ì„œ ìƒì„¸ ì¬ë¬´ ë°ì´í„° ìˆ˜ì§‘ (ì‹¤ì œ í˜ì´ì§€ êµ¬ì¡° ë°˜ì˜)"""
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
    
    try:
        # ë©”ì¸ í˜ì´ì§€ì—ì„œ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘ (ê°€ì¥ ë§ì€ ë°ì´í„°ê°€ ìˆìŒ)
        main_url = f'https://finance.naver.com/item/main.naver?code={code}'
        main_response = requests.get(main_url, headers=headers)
        main_soup = BeautifulSoup(main_response.text, 'html.parser')
        
        # íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ í˜ì´ì§€ì—ì„œ íˆ¬ìì ë¹„ìœ¨ ìˆ˜ì§‘
        investor_url = f'https://finance.naver.com/item/frgn.naver?code={code}'
        investor_response = requests.get(investor_url, headers=headers)
        investor_soup = BeautifulSoup(investor_response.text, 'html.parser')
        
        # ì¬ë¬´ì •ë³´ í˜ì´ì§€ì—ì„œ ìƒì„¸ ì¬ë¬´ ë°ì´í„° ìˆ˜ì§‘
        finance_url = f'https://finance.naver.com/item/coinfo.naver?code={code}&target=finsum_more'
        finance_response = requests.get(finance_url, headers=headers)
        finance_soup = BeautifulSoup(finance_response.text, 'html.parser')
        
        # ì´ˆê¸°í™” (í™•ì¥ëœ ë°ì´í„° í•„ë“œ)
        data = {
            'PER': '', 'PBR': '', 'ROE': '', 'ì‹œê°€ì´ì•¡': '',
            'ë§¤ì¶œì•¡': '', 'ì˜ì—…ì´ìµ': '', 'ë‹¹ê¸°ìˆœì´ìµ': '', 
            'ë¶€ì±„ë¹„ìœ¨': '', 'ìœ ë³´ìœ¨': '', 'ë°°ë‹¹ìˆ˜ìµë¥ ': '', 'ë°°ë‹¹ê¸ˆ': '',
            '52ì£¼ìµœê³ ': '', '52ì£¼ìµœì €': '', 'ê±°ë˜ëŒ€ê¸ˆ': '',
            'ì™¸êµ­ì¸ë¹„ìœ¨': '', 'ê¸°ê´€ë¹„ìœ¨': '', 'ë² íƒ€': '', 'ì—…ì¢…': '',
            'ì˜ì—…ì´ìµë¥ ': '', 'ìˆœì´ìµë¥ ': ''  # ì¶”ê°€ ì§€í‘œ
        }
        
        # 1. ë©”ì¸ í˜ì´ì§€ì—ì„œ ê¸°ë³¸ ë°ì´í„° ì¶”ì¶œ (PER, PBR, ROE ìµœì‹  ë°ì´í„° í¬í•¨)
        extract_main_page_data(main_soup, data)
        
        # 3. íˆ¬ìì í˜ì´ì§€ì—ì„œ íˆ¬ìì ë¹„ìœ¨ ì¶”ì¶œ
        extract_investor_data(investor_soup, data)
        
        # 4. ì¬ë¬´ì •ë³´ í˜ì´ì§€ì—ì„œ ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ
        extract_financial_data(finance_soup, data)
        
        # 5. ë©”ì¸ í˜ì´ì§€ì—ì„œ ì¶”ê°€ ì¬ë¬´ ì •ë³´ ì¶”ì¶œ (ë°±ì—…)
        extract_additional_finance_data(main_soup, data)
        
        # ì •í™•í•œ ìˆœì„œë¡œ ë°ì´í„° ë°˜í™˜ (ê¸°ì¡´ ì½”ë“œì™€ ì¼ì¹˜)
        return (
            name,           # 0: ì¢…ëª©ëª…  
            '',            # 1: í˜„ì¬ê°€
            '',            # 2: ì „ì¼ ëŒ€ë¹„
            data['PER'],   # 3: PER
            data['PBR'],   # 4: PBR  
            data['ROE'],   # 5: ROE
            '',            # 6: ë² íƒ€ (ë‚˜ì¤‘ì— ì¶”ê°€)
            data['ì‹œê°€ì´ì•¡'], # 7: ì‹œê°€ì´ì•¡
            data['ê±°ë˜ëŒ€ê¸ˆ'], # 8: ê±°ë˜ëŒ€ê¸ˆ
            data['ì™¸êµ­ì¸ë¹„ìœ¨'], # 9: ì™¸êµ­ì¸ë¹„ìœ¨
            data['ê¸°ê´€ë¹„ìœ¨'],   # 10: ê¸°ê´€ë¹„ìœ¨
            '',              # 11: ê±°ë˜ëŸ‰
            data['ë°°ë‹¹ìˆ˜ìµë¥ '], # 12: ë°°ë‹¹ìˆ˜ìµë¥ 
            data['ë°°ë‹¹ê¸ˆ'],    # 13: ë°°ë‹¹ê¸ˆ
            data['52ì£¼ìµœê³ '],  # 14: 52ì£¼ìµœê³ 
            data['ë§¤ì¶œì•¡'],    # 15: ë§¤ì¶œì•¡
            data['ì˜ì—…ì´ìµ'],  # 16: ì˜ì—…ì´ìµ
            data['ë‹¹ê¸°ìˆœì´ìµ'] # 17: ë‹¹ê¸°ìˆœì´ìµ
        )
        
    except Exception as e:
        print(f"{name} ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
        return ('',) * 18  # 18ê°œ ë¹ˆ ê°’ ë°˜í™˜

def extract_investment_indicators(soup, data):
    """ì¢…ëª©ì •ë³´ í˜ì´ì§€ì˜ íˆ¬ìì§€í‘œ í…Œì´ë¸”ì—ì„œ ìµœì‹  ë°ì´í„° ì¶”ì¶œ (ê°€ì¥ ì˜¤ë¥¸ìª½ ì»¬ëŸ¼)"""
    try:
        tables = soup.find_all('table')
        
        for table in tables:
            table_text = table.get_text()
            
            # íˆ¬ìì§€í‘œ í…Œì´ë¸” ì°¾ê¸° (PER, PBR ë“±ì´ í¬í•¨ëœ)
            if any(keyword in table_text for keyword in ['PER', 'PBR', 'ë°°ë‹¹ìˆ˜ìµë¥ ']):
                rows = table.find_all('tr')
                
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 2:  # ìµœì†Œ 2ê°œ ì»¬ëŸ¼
                        first_cell_text = cells[0].get_text(strip=True)
                        
                        # ê°€ì¥ ì˜¤ë¥¸ìª½ ì»¬ëŸ¼(ìµœì‹  ë°ì´í„°)ì—ì„œ ê°’ ì¶”ì¶œ
                        latest_cell_text = cells[-1].get_text(strip=True)
                        
                        # PER ì¶”ì¶œ (ì¶”ì •PER ì œì™¸í•˜ê³  ì •í™•í•œ PERë§Œ)
                        if 'PER' in first_cell_text and 'ì¶”ì •' not in first_cell_text and not data['PER']:
                            # "11.53ë°°l5,162ì›" í˜•íƒœì—ì„œ PER ê°’ ì¶”ì¶œ
                            per_match = re.search(r'([+-]?\d+\.?\d*)ë°°', latest_cell_text)
                            if per_match:
                                per_value = float(per_match.group(1))
                                if 0 < per_value < 1000:  # í•©ë¦¬ì ì¸ PER ë²”ìœ„
                                    data['PER'] = per_match.group(1)
                                    print(f"âœ… PER ì¶”ì¶œ ì„±ê³µ: {data['PER']}")
                        
                        # PBR ì¶”ì¶œ  
                        elif 'PBR' in first_cell_text and not data['PBR']:
                            # "N/Al59,059ì›" ë˜ëŠ” "1.09ë°°l..." í˜•íƒœ
                            if 'N/A' not in latest_cell_text:
                                pbr_match = re.search(r'([+-]?\d+\.?\d*)ë°°?', latest_cell_text)
                                if pbr_match:
                                    pbr_value = float(pbr_match.group(1))
                                    if 0 < pbr_value < 100:  # í•©ë¦¬ì ì¸ PBR ë²”ìœ„
                                        data['PBR'] = pbr_match.group(1)
                                        print(f"âœ… PBR ì¶”ì¶œ ì„±ê³µ: {data['PBR']}")
                        
                        # ë°°ë‹¹ìˆ˜ìµë¥  ì¶”ì¶œ
                        elif 'ë°°ë‹¹ìˆ˜ìµë¥ ' in first_cell_text and not data['ë°°ë‹¹ìˆ˜ìµë¥ ']:
                            # "2.43%" í˜•íƒœ
                            dividend_match = re.search(r'([+-]?\d+\.?\d*)%', latest_cell_text)
                            if dividend_match:
                                data['ë°°ë‹¹ìˆ˜ìµë¥ '] = dividend_match.group(1)
    
    except Exception as e:
        print(f"íˆ¬ìì§€í‘œ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")

def extract_latest_financial_ratios(soup, data):
    """íˆ¬ìì •ë³´ í…Œì´ë¸”ì—ì„œ ìµœì‹  PER, PBR, ROE ì¶”ì¶œ (2025.03 ê¸°ì¤€)"""
    try:
        tables = soup.find_all('table')
        
        for table in tables:
            table_text = table.get_text()
            
            # 2025.03ì´ í¬í•¨ëœ íˆ¬ìì •ë³´ í…Œì´ë¸” ì°¾ê¸°
            if 'PER' in table_text and 'PBR' in table_text and '2025.03' in table_text:
                rows = table.find_all('tr')
                
                # í—¤ë”ì—ì„œ ìµœì‹  ì»¬ëŸ¼ ìœ„ì¹˜ ì°¾ê¸° (2025.06 ìš°ì„ , ì—†ìœ¼ë©´ 2025.03)
                latest_col_index = -1
                if len(rows) >= 2:
                    header_cells = rows[1].find_all(['td', 'th'])  # 2ë²ˆì§¸ í–‰ì´ ë…„ë„ í–‰
                    
                    # 1ìˆœìœ„: 2025.06 ì°¾ê¸°
                    for i, cell in enumerate(header_cells):
                        if '2025.06' in cell.get_text(strip=True):
                            latest_col_index = i
                            print(f"âœ… 2025.06 ì»¬ëŸ¼ ë°œê²¬ (ì»¬ëŸ¼ {i})")
                            break
                    
                    # 2ìˆœìœ„: 2025.06ì´ ì—†ìœ¼ë©´ 2025.03 ì°¾ê¸°  
                    if latest_col_index == -1:
                        for i, cell in enumerate(header_cells):
                            if '2025.03' in cell.get_text(strip=True):
                                latest_col_index = i
                                print(f"âœ… 2025.03 ì»¬ëŸ¼ ë°œê²¬ (ì»¬ëŸ¼ {i})")
                                break
                
                if latest_col_index == -1:
                    continue
                
                # ê° í–‰ì—ì„œ PER, PBR, ROE ì¶”ì¶œ
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) > latest_col_index:
                        first_cell_text = cells[0].get_text(strip=True)
                        latest_value = cells[latest_col_index].get_text(strip=True)
                        
                        # PER ì¶”ì¶œ (PER(ë°°) í–‰)
                        if 'PER' in first_cell_text and 'ë°°' in first_cell_text and not data['PER']:
                            if latest_value and latest_value != '' and latest_value != '-':
                                try:
                                    per_value = float(latest_value)
                                    if 0 < per_value < 1000:
                                        data['PER'] = latest_value
                                        print(f"âœ… ìµœì‹  PER ì¶”ì¶œ (2025.03): {data['PER']}")
                                except:
                                    pass
                        
                        # PBR ì¶”ì¶œ (PBR(ë°°) í–‰)
                        elif 'PBR' in first_cell_text and 'ë°°' in first_cell_text and not data['PBR']:
                            if latest_value and latest_value != '' and latest_value != '-':
                                try:
                                    pbr_value = float(latest_value)
                                    if 0 < pbr_value < 100:
                                        data['PBR'] = latest_value
                                        print(f"âœ… ìµœì‹  PBR ì¶”ì¶œ (2025.03): {data['PBR']}")
                                except:
                                    pass
                        
                        # ROE ì¶”ì¶œ (ROE(ì§€ë°°ì£¼ì£¼) í–‰)
                        elif 'ROE' in first_cell_text and not data['ROE']:
                            if latest_value and latest_value != '' and latest_value != '-':
                                try:
                                    roe_value = float(latest_value)
                                    if -100 <= roe_value <= 100:
                                        data['ROE'] = latest_value
                                        print(f"âœ… ìµœì‹  ROE ì¶”ì¶œ (2025.03): {data['ROE']}")
                                except:
                                    pass
                        
                        # ë§¤ì¶œì•¡ ì¶”ì¶œ
                        elif 'ë§¤ì¶œì•¡' in first_cell_text and not data['ë§¤ì¶œì•¡']:
                            if latest_value and latest_value != '' and latest_value != '-':
                                data['ë§¤ì¶œì•¡'] = latest_value
                                print(f"âœ… ìµœì‹  ë§¤ì¶œì•¡ ì¶”ì¶œ (2025.03): {data['ë§¤ì¶œì•¡']}")
                        
                        # ì˜ì—…ì´ìµ ì¶”ì¶œ
                        elif 'ì˜ì—…ì´ìµ' in first_cell_text and not data['ì˜ì—…ì´ìµ']:
                            if latest_value and latest_value != '' and latest_value != '-':
                                data['ì˜ì—…ì´ìµ'] = latest_value
                                print(f"âœ… ìµœì‹  ì˜ì—…ì´ìµ ì¶”ì¶œ (2025.03): {data['ì˜ì—…ì´ìµ']}")
                        
                        # ë‹¹ê¸°ìˆœì´ìµ ì¶”ì¶œ
                        elif 'ë‹¹ê¸°ìˆœì´ìµ' in first_cell_text and not data['ë‹¹ê¸°ìˆœì´ìµ']:
                            if latest_value and latest_value != '' and latest_value != '-':
                                data['ë‹¹ê¸°ìˆœì´ìµ'] = latest_value
                                print(f"âœ… ìµœì‹  ë‹¹ê¸°ìˆœì´ìµ ì¶”ì¶œ (2025.03): {data['ë‹¹ê¸°ìˆœì´ìµ']}")
                        
                        # ì˜ì—…ì´ìµë¥  ì¶”ì¶œ
                        elif 'ì˜ì—…ì´ìµë¥ ' in first_cell_text and not data.get('ì˜ì—…ì´ìµë¥ '):
                            if latest_value and latest_value != '' and latest_value != '-':
                                data['ì˜ì—…ì´ìµë¥ '] = latest_value
                                print(f"âœ… ìµœì‹  ì˜ì—…ì´ìµë¥  ì¶”ì¶œ (2025.03): {data['ì˜ì—…ì´ìµë¥ ']}")
                        
                        # ìˆœì´ìµë¥  ì¶”ì¶œ (ì¶”ê°€ ì§€í‘œ)
                        elif 'ìˆœì´ìµë¥ ' in first_cell_text and not data.get('ìˆœì´ìµë¥ '):
                            if latest_value and latest_value != '' and latest_value != '-':
                                data['ìˆœì´ìµë¥ '] = latest_value
                                print(f"âœ… ìµœì‹  ìˆœì´ìµë¥  ì¶”ì¶œ (2025.03): {data['ìˆœì´ìµë¥ ']}")
                
                break  # í…Œì´ë¸” ì°¾ì•˜ìœ¼ë©´ ì¢…ë£Œ
    
    except Exception as e:
        print(f"ìµœì‹  ì¬ë¬´ë¹„ìœ¨ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")

def extract_main_page_data(soup, data):
    """ë©”ì¸ í˜ì´ì§€ì—ì„œ ê¸°ë³¸ ë°ì´í„° ì¶”ì¶œ"""
    try:
        # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì •ê·œì‹ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ
        page_text = soup.get_text()
        
        # íˆ¬ìì •ë³´ í…Œì´ë¸”ì—ì„œ ìµœì‹  PER, PBR, ROE ì¶”ì¶œ (2025.03 ê¸°ì¤€)
        extract_latest_financial_ratios(soup, data)
        
        # 52ì£¼ ìµœê³ /ìµœì € (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
        # íŒ¨í„´ 1: "88,800l49,900" í˜•íƒœ
        combined_52_match = re.search(r'52ì£¼ìµœê³ lìµœì €[^\d]*?([,\d]+)l([,\d]+)', page_text)
        if combined_52_match:
            data['52ì£¼ìµœê³ '] = combined_52_match.group(1).replace(',', '')
            data['52ì£¼ìµœì €'] = combined_52_match.group(2).replace(',', '')
        else:
            # íŒ¨í„´ 2: ë³„ë„ë¡œ ì°¾ê¸°
            high_52_match = re.search(r'52ì£¼ìµœê³ [^\d]*?([,\d]+)', page_text)
            if high_52_match:
                data['52ì£¼ìµœê³ '] = high_52_match.group(1).replace(',', '')
            
            # íŒ¨í„´ 3: "ìµœê³  88,800 ìµœì € 49,900" ê°™ì€ íŒ¨í„´
            high_low_match = re.search(r'ìµœê³ [^\d]*?([,\d]+)[^\d]*?ìµœì €[^\d]*?([,\d]+)', page_text)
            if high_low_match:
                if not data['52ì£¼ìµœê³ ']:
                    data['52ì£¼ìµœê³ '] = high_low_match.group(1).replace(',', '')
                data['52ì£¼ìµœì €'] = high_low_match.group(2).replace(',', '')
            
            # íŒ¨í„´ 4: "l 49,900" ê°™ì€ ë‹¨ë… íŒ¨í„´ (ìµœì €ê°’)
            if not data['52ì£¼ìµœì €']:
                low_only_match = re.search(r'l\s*([,\d]+)', page_text)
                if low_only_match:
                    low_value = low_only_match.group(1).replace(',', '')
                    # í˜„ì¬ê°€ë³´ë‹¤ ë‚®ì€ ê°’ë§Œ ìµœì €ë¡œ ì¸ì •
                    if len(low_value) >= 4:  # ìµœì†Œ 4ìë¦¬ ì´ìƒ
                        data['52ì£¼ìµœì €'] = low_value
        
        # ì‹œê°€ì´ì•¡ (ì–µì› ë‹¨ìœ„)
        market_cap_match = re.search(r'ì‹œê°€ì´ì•¡[^\d]*?([,\d]+)ì¡°?[,\d]*ì–µ?ì›?', page_text)
        if market_cap_match:
            # ì¡° ë‹¨ìœ„ë¥¼ ì–µ ë‹¨ìœ„ë¡œ ë³€í™˜
            cap_str = market_cap_match.group(1).replace(',', '')
            if 'ì¡°' in market_cap_match.group(0):
                cap_value = int(cap_str) * 10000  # ì¡° -> ì–µ ë³€í™˜
                data['ì‹œê°€ì´ì•¡'] = str(cap_value)
            else:
                data['ì‹œê°€ì´ì•¡'] = cap_str
        
        # ê±°ë˜ëŒ€ê¸ˆ (ë°±ë§Œì›)
        trading_match = re.search(r'ê±°ë˜ëŒ€ê¸ˆ[^\d]*?([,\d]+)[^\d]*?ë°±ë§Œ', page_text)
        if trading_match:
            data['ê±°ë˜ëŒ€ê¸ˆ'] = trading_match.group(1).replace(',', '')
        
        # ë°°ë‹¹ìˆ˜ìµë¥  - ì •í™•í•œ ê°’ ì°¾ê¸° (2.43% ê°™ì€ í˜•íƒœ)
        if not data['ë°°ë‹¹ìˆ˜ìµë¥ ']:
            # ë¨¼ì € "ë°°ë‹¹ìˆ˜ìµë¥ " ë¬¸êµ¬ ì£¼ë³€ì—ì„œ ì°¾ê¸°
            dividend_section = re.search(r'ë°°ë‹¹ìˆ˜ìµë¥ [^%]*?([+-]?\d+\.?\d*)%', page_text)
            if dividend_section:
                try:
                    value = float(dividend_section.group(1))
                    if 0 <= value <= 20:
                        data['ë°°ë‹¹ìˆ˜ìµë¥ '] = dividend_section.group(1)
                        print(f"âœ… ë©”ì¸í˜ì´ì§€ ë°°ë‹¹ìˆ˜ìµë¥  ì¶”ì¶œ: {data['ë°°ë‹¹ìˆ˜ìµë¥ ']}%")
                except:
                    pass
            
            # ë°±ì—…: 2.43% ê°™ì€ í˜•íƒœì˜ ë°°ë‹¹ ìˆ˜ìµë¥  íŒ¨í„´
            if not data['ë°°ë‹¹ìˆ˜ìµë¥ ']:
                all_percentages = re.findall(r'([+-]?\d+\.?\d*)%', page_text)
                for pct in all_percentages:
                    try:
                        value = float(pct)
                        if 1 <= value <= 10:  # ì¼ë°˜ì ì¸ ë°°ë‹¹ìˆ˜ìµë¥  ë²”ìœ„
                            # í•´ë‹¹ ìˆ«ì ì£¼ë³€ì— 'ë°°ë‹¹' ê´€ë ¨ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
                            pattern = rf'ë°°ë‹¹[^%]*?{re.escape(pct)}%'
                            if re.search(pattern, page_text):
                                data['ë°°ë‹¹ìˆ˜ìµë¥ '] = pct
                                print(f"âœ… ë©”ì¸í˜ì´ì§€ ë°°ë‹¹ìˆ˜ìµë¥  ì¶”ì¶œ: {data['ë°°ë‹¹ìˆ˜ìµë¥ ']}%")
                                break
                    except:
                        continue
        
        # í…Œì´ë¸”ì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
        tables = soup.find_all('table')
        for table in tables:
            rows = table.find_all('tr')
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 2:
                    for i, cell in enumerate(cells[:-1]):
                        cell_text = cell.get_text(strip=True)
                        next_cell_text = cells[i+1].get_text(strip=True)
                        
                        # ë² íƒ€ ì •ë³´
                        if 'ë² íƒ€' in cell_text and not data['ë² íƒ€']:
                            beta_match = re.search(r'([+-]?\d+\.?\d*)', next_cell_text)
                            if beta_match:
                                data['ë² íƒ€'] = beta_match.group(1)
                        
                        # ì—…ì¢… ì •ë³´
                        elif 'ì—…ì¢…' in cell_text and not data['ì—…ì¢…']:
                            # ìˆ«ìê°€ ì•„ë‹Œ í…ìŠ¤íŠ¸ë§Œ ì—…ì¢…ìœ¼ë¡œ ì¸ì •
                            sector_text = next_cell_text.strip()
                            if sector_text and not re.match(r'^[\d.,]+', sector_text):
                                data['ì—…ì¢…'] = sector_text
        
        # ì™¸êµ­ì¸ ë³´ìœ ë¹„ìœ¨ (ë©”ì¸í˜ì´ì§€ì—ì„œë„ ê°€ëŠ¥í•œ ê²½ìš°)
        foreign_match = re.search(r'ì™¸êµ­ì¸[^\d]*?([+-]?\d+\.?\d*)%', page_text)
        if foreign_match and not data['ì™¸êµ­ì¸ë¹„ìœ¨']:
            data['ì™¸êµ­ì¸ë¹„ìœ¨'] = foreign_match.group(1)
    
    except Exception as e:
        print(f"ë©”ì¸ í˜ì´ì§€ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")

def extract_financial_data(soup, data):
    """ì¬ë¬´ì •ë³´ í˜ì´ì§€ì—ì„œ ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ"""
    try:
        # ì¬ë¬´ì œí‘œ í…Œì´ë¸”ì—ì„œ ìµœì‹  ì—°ë„ ë°ì´í„° ì¶”ì¶œ
        tables = soup.find_all('table')
        for table in tables:
            table_text = table.get_text()
            
            # ì¬ë¬´ì œí‘œ í…Œì´ë¸” ì°¾ê¸°
            if 'ë§¤ì¶œì•¡' in table_text or 'ì˜ì—…ì´ìµ' in table_text:
                rows = table.find_all('tr')
                if len(rows) > 1:
                    # í—¤ë”ì—ì„œ ìµœì‹  ì—°ë„ ì»¬ëŸ¼ ì°¾ê¸° (2024ë…„ ìš°ì„ )
                    header_row = rows[0]
                    year_cells = header_row.find_all(['th', 'td'])
                    latest_col_index = 1  # ê¸°ë³¸ê°’
                    
                    for i, cell in enumerate(year_cells[1:], 1):
                        cell_text = cell.get_text(strip=True)
                        if '2024' in cell_text or '24/12' in cell_text:
                            latest_col_index = i
                            break
                        elif '2023' in cell_text or '23/12' in cell_text and latest_col_index == 1:
                            latest_col_index = i
                    
                    # ê° ì¬ë¬´ í•­ëª© ì¶”ì¶œ
                    for row in rows[1:]:
                        cells = row.find_all(['td', 'th'])
                        if len(cells) > latest_col_index:
                            item_name = cells[0].get_text(strip=True)
                            latest_value = cells[latest_col_index].get_text(strip=True)
                            
                            # ë§¤ì¶œì•¡
                            if 'ë§¤ì¶œì•¡' in item_name and not data['ë§¤ì¶œì•¡']:
                                value_match = re.search(r'([,\d]+)', latest_value.replace(',', ''))
                                if value_match:
                                    data['ë§¤ì¶œì•¡'] = value_match.group(1)
                            
                            # ì˜ì—…ì´ìµ
                            elif 'ì˜ì—…ì´ìµ' in item_name and not data['ì˜ì—…ì´ìµ']:
                                value_match = re.search(r'([+-]?[,\d]+)', latest_value.replace(',', ''))
                                if value_match:
                                    data['ì˜ì—…ì´ìµ'] = value_match.group(1)
                            
                            # ë‹¹ê¸°ìˆœì´ìµ
                            elif ('ë‹¹ê¸°ìˆœì´ìµ' in item_name or 'ìˆœì´ìµ' in item_name) and not data['ë‹¹ê¸°ìˆœì´ìµ']:
                                value_match = re.search(r'([+-]?[,\d]+)', latest_value.replace(',', ''))
                                if value_match:
                                    data['ë‹¹ê¸°ìˆœì´ìµ'] = value_match.group(1)
                            
                            # ROE
                            elif 'ROE' in item_name and not data['ROE']:
                                value_match = re.search(r'([+-]?\d+\.?\d*)', latest_value)
                                if value_match:
                                    data['ROE'] = value_match.group(1)
                            
                            # ë¶€ì±„ë¹„ìœ¨
                            elif 'ë¶€ì±„ë¹„ìœ¨' in item_name and not data['ë¶€ì±„ë¹„ìœ¨']:
                                value_match = re.search(r'([+-]?\d+\.?\d*)', latest_value)
                                if value_match:
                                    data['ë¶€ì±„ë¹„ìœ¨'] = value_match.group(1)
                            
                            # ìœ ë³´ìœ¨
                            elif 'ìœ ë³´ìœ¨' in item_name and not data['ìœ ë³´ìœ¨']:
                                value_match = re.search(r'([+-]?\d+\.?\d*)', latest_value)
                                if value_match:
                                    data['ìœ ë³´ìœ¨'] = value_match.group(1)
                            
                            # ë°°ë‹¹ê¸ˆ
                            elif 'ë°°ë‹¹ê¸ˆ' in item_name and not data['ë°°ë‹¹ê¸ˆ']:
                                value_match = re.search(r'([,\d]+)', latest_value.replace(',', ''))
                                if value_match:
                                    data['ë°°ë‹¹ê¸ˆ'] = value_match.group(1)
    
    except Exception as e:
        print(f"ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")

def extract_investor_data(soup, data):
    """íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ í˜ì´ì§€ì—ì„œ íˆ¬ìì ë¹„ìœ¨ ë° ê±°ë˜ ë°ì´í„° ì¶”ì¶œ"""
    try:
        # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì™¸êµ­ì¸/ê¸°ê´€ ë¹„ìœ¨ ì¶”ì¶œ
        page_text = soup.get_text()
        
        # ì™¸êµ­ì¸ ì†Œì§„ìœ¨ ë˜ëŠ” ë³´ìœ ìœ¨
        foreign_patterns = [
            r'ì™¸êµ­ì¸ì†Œì§„ìœ¨[^\d]*?([+-]?\d+\.?\d*)%',
            r'ì™¸êµ­ì¸ë³´ìœ ìœ¨[^\d]*?([+-]?\d+\.?\d*)%',
            r'ì™¸êµ­ì¸[^\d]*?([+-]?\d+\.?\d*)%'
        ]
        
        for pattern in foreign_patterns:
            foreign_match = re.search(pattern, page_text)
            if foreign_match and not data['ì™¸êµ­ì¸ë¹„ìœ¨']:
                data['ì™¸êµ­ì¸ë¹„ìœ¨'] = foreign_match.group(1)
                break
        
        # í…Œì´ë¸”ì—ì„œ ì •í™•í•œ íˆ¬ìì ë¹„ìœ¨ ì°¾ê¸°
        tables = soup.find_all('table')
        for table in tables:
            if 'ì™¸êµ­ì¸' in table.get_text():
                rows = table.find_all('tr')
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 2:
                        for i, cell in enumerate(cells[:-1]):
                            cell_text = cell.get_text(strip=True)
                            next_cell_text = cells[i+1].get_text(strip=True)
                            
                            # ì™¸êµ­ì¸ ë¹„ìœ¨
                            if 'ì™¸êµ­ì¸' in cell_text and '%' in next_cell_text and not data['ì™¸êµ­ì¸ë¹„ìœ¨']:
                                value_match = re.search(r'([+-]?\d+\.?\d*)', next_cell_text)
                                if value_match:
                                    data['ì™¸êµ­ì¸ë¹„ìœ¨'] = value_match.group(1)
                            
                            # ê¸°ê´€ ë¹„ìœ¨
                            elif 'ê¸°ê´€' in cell_text and '%' in next_cell_text and not data['ê¸°ê´€ë¹„ìœ¨']:
                                value_match = re.search(r'([+-]?\d+\.?\d*)', next_cell_text)
                                if value_match:
                                    data['ê¸°ê´€ë¹„ìœ¨'] = value_match.group(1)
    
    except Exception as e:
        print(f"íˆ¬ìì ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")

def extract_price_data(soup, data):
    """ë©”ì¸ í˜ì´ì§€ì—ì„œ ê¸°ë³¸ ì‹œì„¸ ë°ì´í„° ì¶”ì¶œ"""
    try:
        # 52ì£¼ ìµœê³ /ìµœì €, ì‹œê°€ì´ì•¡, ë² íƒ€ ë“± ì¶”ì¶œ
        tables = soup.find_all('table')
        for table in tables:
            rows = table.find_all('tr')
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 2:
                    for i, cell in enumerate(cells[:-1]):
                        cell_text = cell.get_text(strip=True)
                        next_cell_text = cells[i+1].get_text(strip=True)
                        
                        # 52ì£¼ ìµœê³ 
                        if '52ì£¼ìµœê³ ' in cell_text and not data['52ì£¼ìµœê³ ']:
                            value_match = re.search(r'([,\d]+)', next_cell_text)
                            if value_match:
                                data['52ì£¼ìµœê³ '] = value_match.group(1).replace(',', '')
                        
                        # 52ì£¼ ìµœì €
                        elif '52ì£¼ìµœì €' in cell_text and not data['52ì£¼ìµœì €']:
                            value_match = re.search(r'([,\d]+)', next_cell_text)
                            if value_match:
                                data['52ì£¼ìµœì €'] = value_match.group(1).replace(',', '')
                        
                        # ì‹œê°€ì´ì•¡
                        elif 'ì‹œê°€ì´ì•¡' in cell_text and not data['ì‹œê°€ì´ì•¡']:
                            value_match = re.search(r'([,\d]+)', next_cell_text)
                            if value_match:
                                data['ì‹œê°€ì´ì•¡'] = value_match.group(1).replace(',', '')
                        
                        # ë² íƒ€
                        elif 'ë² íƒ€' in cell_text and not data['ë² íƒ€']:
                            value_match = re.search(r'([+-]?\d+\.?\d*)', next_cell_text)
                            if value_match:
                                data['ë² íƒ€'] = value_match.group(1)
        
        # ê±°ë˜ëŒ€ê¸ˆ ì •ë³´ (ì•„ì§ ì—†ë‹¤ë©´)
        if not data['ê±°ë˜ëŒ€ê¸ˆ']:
            page_text = soup.get_text()
            trading_match = re.search(r'ê±°ë˜ëŒ€ê¸ˆ[^\d]*([,\d]+)', page_text)
            if trading_match:
                data['ê±°ë˜ëŒ€ê¸ˆ'] = trading_match.group(1).replace(',', '')
    
    except Exception as e:
        print(f"ì‹œì„¸ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")

def extract_additional_finance_data(soup, data):
    """ë©”ì¸ í˜ì´ì§€ì—ì„œ ì¶”ê°€ ì¬ë¬´ ì •ë³´ ì¶”ì¶œ (ë°±ì—…ìš©)"""
    try:
        page_text = soup.get_text()
        
        # ROE íŒ¨í„´ ì°¾ê¸°
        if not data['ROE']:
            roe_patterns = [
                r'ROE[^\d]*?([+-]?\d+\.?\d*)%?',
                r'ìê¸°ìë³¸ì´ìµë¥ [^\d]*?([+-]?\d+\.?\d*)%?'
            ]
            for pattern in roe_patterns:
                roe_match = re.search(pattern, page_text)
                if roe_match:
                    value = float(roe_match.group(1))
                    if -100 <= value <= 100:  # í•©ë¦¬ì ì¸ ROE ë²”ìœ„
                        data['ROE'] = roe_match.group(1)
                        break
        
        # ë² íƒ€ ì •ë³´ ì¬ì‹œë„
        if not data['ë² íƒ€']:
            # í…Œì´ë¸”ì—ì„œ ë² íƒ€ ì°¾ê¸°
            tables = soup.find_all('table')
            for table in tables:
                if 'ë² íƒ€' in table.get_text():
                    rows = table.find_all('tr')
                    for row in rows:
                        cells = row.find_all(['td', 'th'])
                        for i, cell in enumerate(cells[:-1]):
                            if 'ë² íƒ€' in cell.get_text() and i+1 < len(cells):
                                beta_text = cells[i+1].get_text(strip=True)
                                beta_match = re.search(r'([+-]?\d+\.?\d*)', beta_text)
                                if beta_match:
                                    data['ë² íƒ€'] = beta_match.group(1)
                                    break
        
        # ì‹œê°€ì´ì•¡ ì •ì • (ì¡° ë‹¨ìœ„ ë³€í™˜ ì¬í™•ì¸)
        if data['ì‹œê°€ì´ì•¡']:
            # í˜„ì¬ ê°’ì´ ì¡° ë‹¨ìœ„ì¸ì§€ í™•ì¸í•˜ê³  ë³€í™˜
            cap_value = data['ì‹œê°€ì´ì•¡'].replace(',', '')
            if len(cap_value) <= 4:  # ì¡° ë‹¨ìœ„ë¡œ ì¶”ì •
                data['ì‹œê°€ì´ì•¡'] = str(int(cap_value) * 10000)
    
    except Exception as e:
        print(f"ì¶”ê°€ ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")

def get_stock_data():
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}
    stock_data = []
    
    for market_type in [0, 1]:
        market_name = "ì½”ìŠ¤í”¼" if market_type == 0 else "ì½”ìŠ¤ë‹¥"
        print(f"\n{market_name} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        # ì „ì²´ í˜ì´ì§€ ìˆ˜ í™•ì¸
        url = f'https://finance.naver.com/sise/sise_market_sum.naver?sosok={market_type}&page=1'
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        max_page = 1
        page_nav = soup.select('td.pgRR > a')
        if page_nav:
            max_page = int(page_nav[0]['href'].split('=')[-1])
        
        print(f"{market_name} ì „ì²´ í˜ì´ì§€ ìˆ˜: {max_page}")
        
        # ì „ì²´ í˜ì´ì§€ ìˆ˜ì§‘
        for page in range(1, max_page + 1):
            print(f"í˜ì´ì§€ {page}/{max_page} ìˆ˜ì§‘ ì¤‘...")
            url = f'https://finance.naver.com/sise/sise_market_sum.naver?sosok={market_type}&page={page}'
            response = requests.get(url, headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            rows = soup.select('table.type_2 tr')[1:]
            if not rows:
                break
            
            collected = 0
            for row in rows:
                cols = row.select('td')
                if len(cols) <= 1:
                    continue
                
                try:
                    name_element = cols[1].select_one('a')
                    if not name_element:
                        continue
                    
                    name = name_element.text.strip()
                    if not is_regular_stock(name):
                        continue
                    
                    code = name_element['href'].split('=')[-1]
                    current_price = cols[2].text.strip().replace(',', '')
                    current_volume = cols[9].text.strip().replace(',', '') if len(cols) > 9 else ''
                    
                    # ê°œë³„ ì¢…ëª© í˜ì´ì§€ì—ì„œ ìƒì„¸ ë°ì´í„° ìˆ˜ì§‘
                    time.sleep(0.3)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
                    (per, pbr, roe, market_cap, sales, operating_profit, net_income, 
                     debt_ratio, retention_ratio, dividend_yield, dividend,
                     high_52w, low_52w, trading_value, foreign_ratio, 
                     institutional_ratio, beta, sector) = get_individual_stock_data(code, name)
                    
                    # ETF/í€ë“œ ì¶”ê°€ í•„í„°ë§: PER, PBR, ROEê°€ ëª¨ë‘ ë¹„ì–´ìˆìœ¼ë©´ ì œì™¸
                    if not per and not pbr and not roe:
                        print(f"  - {name}: PER/PBR/ROE ë°ì´í„° ì—†ìŒ (ETF/í€ë“œë¡œ ì¶”ì •) - ì œì™¸")
                        continue
                    
                    # ì¼ë³„ ì‹œì„¸ í˜ì´ì§€ì—ì„œ ì „ì¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    time.sleep(0.1)
                    daily_url = f'https://finance.naver.com/item/sise_day.naver?code={code}'
                    daily_response = requests.get(daily_url, headers=headers)
                    daily_soup = BeautifulSoup(daily_response.text, 'html.parser')
                    
                    daily_rows = daily_soup.select('table.type2 tr')
                    valid_rows = [r for r in daily_rows if r.select('td.num')]
                    
                    prev_close = ''
                    prev_volume = ''
                    if len(valid_rows) >= 2:
                        yesterday_row = valid_rows[1]
                        yesterday_cols = yesterday_row.select('td.num')
                        if len(yesterday_cols) >= 6:
                            prev_close = yesterday_cols[0].text.strip().replace(',', '')
                            prev_volume = yesterday_cols[5].text.strip().replace(',', '')
                    
                    # ê±°ë˜ëŸ‰ ì¦ê°ìœ¨ ê³„ì‚°
                    volume_change_rate = calculate_volume_change_rate(current_volume, prev_volume)
                    
                    if all([name, code, current_price]):
                        stock_data.append({
                            'ì¢…ëª©ëª…': name,
                            'ì¢…ëª©ì½”ë“œ': code,
                            'ì‹œì¥êµ¬ë¶„': market_name,
                            'ì—…ì¢…': sector,
                            'í˜„ì¬ê°€': current_price,
                            'ì „ì¼ì¢…ê°€': prev_close,
                            'ê±°ë˜ëŸ‰': current_volume,
                            'ì „ì¼ê±°ë˜ëŸ‰': prev_volume,
                            'ê±°ë˜ëŸ‰ì¦ê°ìœ¨': volume_change_rate,
                            'ê±°ë˜ëŒ€ê¸ˆ': trading_value,
                            'PER': per,
                            'PBR': pbr,
                            'ROE': roe,
                            'ì‹œê°€ì´ì•¡': market_cap,
                            'ë§¤ì¶œì•¡': sales,
                            'ì˜ì—…ì´ìµ': operating_profit,
                            'ë‹¹ê¸°ìˆœì´ìµ': net_income,
                            'ë¶€ì±„ë¹„ìœ¨': debt_ratio,
                            'ìœ ë³´ìœ¨': retention_ratio,
                            'ë°°ë‹¹ìˆ˜ìµë¥ ': dividend_yield,
                            'ë°°ë‹¹ê¸ˆ': dividend,
                            '52ì£¼ìµœê³ ': high_52w,
                            '52ì£¼ìµœì €': low_52w,
                            'ì™¸êµ­ì¸ë¹„ìœ¨': foreign_ratio,
                            'ê¸°ê´€ë¹„ìœ¨': institutional_ratio,
                            'ë² íƒ€': beta,
                            'ìˆ˜ì§‘ì¼ì': datetime.now().strftime('%Y-%m-%d')
                        })
                        collected += 1
                        
                        # ì§„í–‰ìƒí™© ì¶œë ¥
                        if collected % 10 == 0:
                            print(f"  - {collected}ê°œ ì¢…ëª© ìˆ˜ì§‘ ì™„ë£Œ (ìµœê·¼: {name} - ì—…ì¢…: {sector})")
                
                except Exception as e:
                    print(f"ì˜¤ë¥˜ ë°œìƒ - ì¢…ëª©: {name if 'name' in locals() else 'ì•Œ ìˆ˜ ì—†ìŒ'}, ì˜¤ë¥˜: {str(e)}")
                    continue
            
            print(f"í˜ì´ì§€ {page}ì—ì„œ {collected}ê°œ ì¢…ëª© ìˆ˜ì§‘ ì™„ë£Œ")
            
            # ì¤‘ê°„ ì €ì¥ (5í˜ì´ì§€ë§ˆë‹¤, ë¡œì»¬ì—ë§Œ)
            if page % 5 == 0:
                temp_df = pd.DataFrame(stock_data)
                temp_filename = f'temp_stock_data_{datetime.now().strftime("%Y%m%d_%H%M")}_{page}.xlsx'
                temp_df.to_excel(temp_filename, index=False)
                print(f"ì¤‘ê°„ ì €ì¥ (ë¡œì»¬): {temp_filename}")
    
    return stock_data

def main():
    print("=== ì „ì²´ ì¢…ëª© ìƒì„¸ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ===")
    print("ìˆ˜ì§‘ ë°ì´í„°: 26ê°œ í•„ë“œ (ì¬ë¬´ì§€í‘œ, íˆ¬ììì •ë³´, ë°°ë‹¹ì •ë³´, ê±°ë˜ëŸ‰ì¦ê°ìœ¨ ë“±)")
    print("ì˜ˆìƒ ì†Œìš”ì‹œê°„: 3-4ì‹œê°„ (ì „ì²´ ì¢…ëª© ì•½ 2000-3000ê°œ)")
    print("ì£¼ì˜: ìˆ˜ì§‘ ì¤‘ ì¤‘ë‹¨í•˜ì§€ ë§ˆì„¸ìš”. 5í˜ì´ì§€ë§ˆë‹¤ ë¡œì»¬ì— ì¤‘ê°„ ì €ì¥ë©ë‹ˆë‹¤.\n")
    
    start_time = datetime.now()
    stock_data = get_stock_data()
    end_time = datetime.now()
    
    if stock_data:
        df = pd.DataFrame(stock_data)
        filename = f'full_stock_data_detailed_{datetime.now().strftime("%Y%m%d_%H%M")}.xlsx'
        df.to_excel(filename, index=False)
        
        print(f"\nğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ì´ {len(stock_data)}ê°œ ì¢…ëª©ì˜ ìƒì„¸ ë°ì´í„°ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ì†Œìš”ì‹œê°„: {end_time - start_time}")
        
        # ë°ì´í„° í’ˆì§ˆ í™•ì¸
        print(f"\nğŸ“Š ë°ì´í„° í’ˆì§ˆ:")
        print(f"PER ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['PER'].notna().sum()}/{len(df)}")
        print(f"PBR ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['PBR'].notna().sum()}/{len(df)}")
        print(f"ROE ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['ROE'].notna().sum()}/{len(df)}")
        print(f"ì‹œê°€ì´ì•¡ ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['ì‹œê°€ì´ì•¡'].notna().sum()}/{len(df)}")
        print(f"ì—…ì¢… ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['ì—…ì¢…'].notna().sum()}/{len(df)}")
        print(f"ë§¤ì¶œì•¡ ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['ë§¤ì¶œì•¡'].notna().sum()}/{len(df)}")
        print(f"ë°°ë‹¹ìˆ˜ìµë¥  ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['ë°°ë‹¹ìˆ˜ìµë¥ '].notna().sum()}/{len(df)}")
        print(f"ê±°ë˜ëŸ‰ì¦ê°ìœ¨ ë°ì´í„° ìˆëŠ” ì¢…ëª©: {df['ê±°ë˜ëŸ‰ì¦ê°ìœ¨'].notna().sum()}/{len(df)}")
        
        # ì‹œê°€ì´ì•¡ë³„ ë¶„í¬ í™•ì¸
        df['ì‹œê°€ì´ì•¡'] = pd.to_numeric(df['ì‹œê°€ì´ì•¡'], errors='coerce')
        print(f"\nğŸ“ˆ ì‹œê°€ì´ì•¡ ë¶„í¬:")
        print(f"10ì¡° ì´ìƒ ëŒ€í˜•ì£¼: {(df['ì‹œê°€ì´ì•¡'] >= 100000).sum()}ê°œ")
        print(f"1ì¡°~10ì¡° ì¤‘í˜•ì£¼: {((df['ì‹œê°€ì´ì•¡'] >= 10000) & (df['ì‹œê°€ì´ì•¡'] < 100000)).sum()}ê°œ")
        print(f"1ì¡° ë¯¸ë§Œ ì†Œí˜•ì£¼: {(df['ì‹œê°€ì´ì•¡'] < 10000).sum()}ê°œ")
        
        # ê±°ë˜ëŸ‰ ì¦ê°ìœ¨ í†µê³„
        df['ê±°ë˜ëŸ‰ì¦ê°ìœ¨_num'] = pd.to_numeric(df['ê±°ë˜ëŸ‰ì¦ê°ìœ¨'], errors='coerce')
        volume_stats = df['ê±°ë˜ëŸ‰ì¦ê°ìœ¨_num'].describe()
        print(f"\nğŸ“Š ê±°ë˜ëŸ‰ ì¦ê°ìœ¨ í†µê³„:")
        print(f"í‰ê· : {volume_stats['mean']:.2f}%")
        print(f"ì¤‘ì•™ê°’: {volume_stats['50%']:.2f}%")
        print(f"ìµœëŒ€: {volume_stats['max']:.2f}%")
        print(f"ìµœì†Œ: {volume_stats['min']:.2f}%")
        
        # ì—…ì¢…ë³„ ë¶„í¬ í™•ì¸
        print(f"\nğŸ¢ ì—…ì¢…ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
        sector_counts = df['ì—…ì¢…'].value_counts().head(10)
        for sector, count in sector_counts.items():
            print(f"{sector}: {count}ê°œ")
        
        # êµ¬ê¸€ ì‹œíŠ¸ ì—…ë¡œë“œ
        print(f"\nğŸ“¤ êµ¬ê¸€ ì‹œíŠ¸ ì—…ë¡œë“œ ì‹œì‘...")
        uploader = GoogleSheetsUploader()
        
        if uploader.gc:  # êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°ì´ ì„±ê³µí•œ ê²½ìš°
            # ê¸°ì¡´ Stock Analyzerì™€ ë™ì¼í•œ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì‚¬ìš©
            today = datetime.now().strftime('%Y-%m-%d')
            spreadsheet_name = f"ì£¼ì‹ë¶„ì„ê²°ê³¼_{today}"
            sheet_name = f"ğŸ’¾_ì „ì²´ì¢…ëª©ë°ì´í„°_{datetime.now().strftime('%H%M')}"
            
            success = uploader.upload_dataframe(df, spreadsheet_name, sheet_name)
            
            if success:
                # í—¤ë” í¬ë§· ì ìš©
                uploader.format_sheet_headers(spreadsheet_name, sheet_name)
                
                # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URL ì¶œë ¥
                url = uploader.get_spreadsheet_url(spreadsheet_name)
                if url:
                    print(f"ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ ë§í¬: {url}")
                    
                print(f"âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—…ë¡œë“œ ì™„ë£Œ!")
                print(f"ğŸ“‹ ì‹œíŠ¸ëª…: {sheet_name}")
                print(f"ğŸ“ ê¸°ì¡´ ì—­ë°œìƒ íˆ¬ì ë°ì´í„°ì™€ ë™ì¼í•œ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ìƒˆ ì‹œíŠ¸ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                print(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—…ë¡œë“œ ì‹¤íŒ¨")
        else:
            print(f"âš ï¸ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨ë¡œ ì¸í•´ ì—…ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            print(f"ğŸ’¾ ì—‘ì…€ íŒŒì¼ë¡œë§Œ ì €ì¥ë¨: {filename}")
            
    else:
        print("\nìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()